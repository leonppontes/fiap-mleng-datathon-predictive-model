# VisÃ£o Geral do Projeto

**Objetivo:** Este projeto resolve o desafio de construir uma pipeline completa de Machine Learning para prever a classificaÃ§Ã£o "Pedra 2024" (Quartzo, Agata, Ametista, TopÃ¡zio) de estudantes baseado em atributos demogrÃ¡ficos (Idade, GÃªnero) e atributos acadÃªmicos (Fase, Ano Ingresso, etc.).

**SoluÃ§Ã£o Proposta:** ConstruÃ§Ã£o de uma pipeline em Python utilizando `scikit-learn` para processamento e treinamento de um modelo *Random Forest*, juntamente com o desenvolvimento de uma API via `FastAPI` para deploy e prediÃ§Ãµes em tempo real. Toda a aplicaÃ§Ã£o foi empacotada com o Docker para garantir que pudesse ser executada com o ambiente de maneira isolada. Testes unitÃ¡rios com o `pytest` alcanÃ§aram >90% de code coverage em todo o projeto.

**Stack TecnolÃ³gica:**
- **Linguagem:** Python 3.12
- **Frameworks de ML:** `scikit-learn`, `pandas`, `numpy`
- **API:** `FastAPI`, `Uvicorn`, `Pydantic`
- **SerializaÃ§Ã£o:** `joblib`
- **Testes:** `pytest`, `pytest-cov`
- **Empacotamento:** `Docker`
- **Monitoramento:** Logging bÃ¡sico estruturado para simulaÃ§Ã£o de detecÃ§Ã£o de drift de dados.

# Estrutura do Projeto (DiretÃ³rios e Arquivos)

```bash
ğŸ“¦ fiap-mleng-datathon-predictive-model
 â”£ ğŸ“‚ app
 â”ƒ â”£ ğŸ“œ main.py                  # Ponto de entrada da API FastAPI
 â”ƒ â”£ ğŸ“œ schemas.py               # Modelos Pydantic (Request/Response)
 â”£ ğŸ“‚ data
 â”ƒ â”£ ğŸ“œ BASE DE DADOS...xlsx     # Base de dados (deve conter a aba PEDE2024)
 â”£ ğŸ“‚ models
 â”ƒ â”£ ğŸ“œ preprocessor.joblib      # Artefato da pipeline de transformaÃ§Ã£o (gerado)
 â”ƒ â”£ ğŸ“œ random_forest_model.joblib # Modelo Random Forest treinado (gerado)
 â”£ ğŸ“‚ src
 â”ƒ â”£ ğŸ“œ config.py                # Caminhos e constantes do sistema
 â”ƒ â”£ ğŸ“œ evaluate.py              # Script para avaliaÃ§Ã£o de mÃ©tricas 
 â”ƒ â”£ ğŸ“œ feature_engineering.py   # Transformadores categÃ³ricos e numÃ©ricos
 â”ƒ â”£ ğŸ“œ preprocessing.py         # Tratamento de nulos e seleÃ§Ã£o de dados
 â”ƒ â”£ ğŸ“œ train.py                 # Script orquestrador de treinamento
 â”ƒ â”£ ğŸ“œ utils.py                 # Fofocas de IO e loggings
 â”£ ğŸ“‚ tests
 â”ƒ â”£ ğŸ“œ test_api.py              # Testes do endpoint de healthcheck
 â”ƒ â”£ ğŸ“œ test_api_predict.py      # Testes do endpoint preditor
 â”ƒ â”£ ğŸ“œ test_feature_engineering.py # Testes dos artefatos de transform
 â”ƒ â”£ ğŸ“œ test_preprocessing.py    # Teste de limpeza de dados
 â”ƒ â”£ ğŸ“œ test_train_evaluate.py   # Testes dos scripts de ML
 â”£ ğŸ“œ Dockerfile                 # Imagem containerizada do ambiente
 â”£ ğŸ“œ README.md                  # Este arquivo
 â”£ ğŸ“œ requirements.txt           # DependÃªncias pip
```

# InstruÃ§Ãµes de Deploy

## Apenas API Local (Sem Docker)

1. Garanta ter o Python 3.12+ em sua mÃ¡quina.
2. Instale as dependÃªncias:
   `pip install -r requirements.txt`
3. Treine o modelo para gerar os arquivos passivos em `/models` antes de testar a base:
   `python src/train.py`
   *(Nota: O script `train.py` Ã© o orquestrador principal. Ele **automaticamente** aciona os mÃ³dulos `preprocessing.py` e `feature_engineering.py` para limpar a base de dados original de Excel e codificar as features antes do treinamento).*
   
4. Avalie as mÃ©tricas:
   `python src/evaluate.py`
5. Rodado a API local:
   `uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload`
6. Rode os testes rodando a bateria com coverage:
   Para que o Python saiba a raiz do pacote dos testes, insira o `PYTHONPATH` antes de rodar o comando:
   No **Windows PowerShell**:
   ```powershell
   $env:PYTHONPATH="."; python -m pytest --cov=src --cov=app tests/
   ```
   No **Linux/Mac**:
   ```bash
   PYTHONPATH="." python -m pytest --cov=src --cov=app tests/
   ```

## Ambiente Containerizado (Docker - Recomendado)

Para subir o sistema isolado em um container:
1. Certifique-se de que treinou o modelo localmente via `python src/train.py` para nÃ£o faltar os arquivos `.joblib` em `./models/` na hora de exportar a imagem. 
2. Construa a Imagem Docker (na pasta raiz):
   ```bash
   docker build -t datathon-model:latest .
   ```
3. Execute o Container:
   ```bash
   docker run -p 8000:8000 datathon-model:latest
   ```
   A aplicaÃ§Ã£o subirÃ¡ no servidor uvicorn apontando para a porta 8000 na sua mÃ¡quina host.

# Exemplos de Chamadas Ã  API

A API expÃµe o endpoint de prediÃ§Ãµes `/predict`. Abaixo exemplos utilizando cURL para validar:

### Health Check 

```bash
curl -X GET http://localhost:8000/
```
**Resposta:**
```json
{
  "status": "ok",
  "message": "API estÃ¡ rodando."
}
```

### Predict 

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
            "Fase": "Fase 8",
            "Idade": 21,
            "Genero": "M",
            "Ano_ingresso": 2021,
            "Instituicao_de_ensino": "VAGA MACRO",
            "Fase_Ideal": "Fase 8",
            "Defasagem": 0
         }'
```
**Resposta Esperada:**
```json
{
  "pedra_2024": "Quartzo",
  "versao_modelo": "1.0.0"
}
```

# Etapas do Pipeline de Machine Learning

Foram codificadas de forma modularizada no diretÃ³rio `src/`:

1. **PrÃ©-processamento dos Dados (`preprocessing.py`):**
   Limpeza bÃ¡sica como dropar dados com variavel target faltante (Pedra 2024=nulo), filtra linhas cujos alvos contÃªm descriÃ§Ãµes invÃ¡lidas sobre os quatro grupos esperados. Preenchimento de dados numÃ©ricos omissos com mediana da prÃ³pria coluna ou strings categÃ³ricas com `"Desconhecido"`.

2. **Engenharia de Features (`feature_engineering.py`):**
   Uso do `ColumnTransformer` (sci-kit learn). A codificaÃ§Ã£o divide atributos:
   - NumÃ©ricos e "Ano ingresso": Escalamento via `StandardScaler` e imputaÃ§Ã£o com Mediana.
   - CategÃ³ricos/Ordinais (`GÃªnero`, `InstituiÃ§Ã£o`, `Fase`): ImputaÃ§Ã£o constante para omissos e One-Hot Encoder para expansÃ£o categÃ³rica vetorial livre de suposiÃ§Ã£o de grandeza. O Transformador compÃµe a "pipeline" completa que depois Ã© unida ao exportÃ¡vel (`joblib`).

3. **Treinamento e ValidaÃ§Ã£o (`train.py` && `evaluate.py`):**
   Treinamento utiliza modelo Random Forest com `class_weight='balanced'` por conta nativa do banco de dados ser desequilibrado nos 4 rÃ³tulos (HÃ¡ massivamente mais classificaÃ§Ã£o de grupo "Quartzo"). Ã‰ utilizado RandomForest por capturar fronteiras nÃ£o lineares sem precisar de otimizaÃ§Ãµes de gradiente robustas ou customizaÃ§Ãµes profundas para obter Ã³timos scores na modelagem.

4. **PersistÃªncia (`utils.py`):**
   O prÃ©-processamento treinado e as matrizes internas de florestas sÃ£o salvas para serem acopladas e enviadas Ã  API sem vazar dados entre as partiÃ§Ãµes.

5. **Monitoramento Local (SimulaÃ§Ã£o de Data Drift):**
   No ambiente atual, implementamos a fundaÃ§Ã£o para o monitoramento de modelos em produÃ§Ã£o utilizando **Logs Estruturados**. 
   - **Como funciona hoje:** Toda vez que a API recebe dados para prediÃ§Ã£o, o mÃ³dulo `app/main.py` registra (log) as caracterÃ­sticas do aluno consultado diretamente na saÃ­da do terminal/container.
   - **EvoluÃ§Ã£o para ProduÃ§Ã£o:** Num cenÃ¡rio real cloud, esses logs de inferÃªncia seriam capturados automaticamente por ferramentas de observabilidade (ex: Datadog, AWS CloudWatch ou a stack ELK - Elasticsearch, Logstash, Kibana). Com os dados centralizados nesses observadores, criarÃ­amos *Dashboards* para comparar a distribuiÃ§Ã£o de atributos (ex: Idade, Fase) enviados pelos usuÃ¡rios contra a distribuiÃ§Ã£o dos dados de quando o modelo foi treinado. Se houver uma divergÃªncia alta (fenÃ´meno conhecido como **Data Drift**), a equipe de dados recebe um alerta indicando que o modelo pode estar perdendo performance e precisa ser retreinado com informaÃ§Ãµes mais recentes.
