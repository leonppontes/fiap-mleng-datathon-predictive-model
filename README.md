# VisÃ£o Geral do Projeto

**Objetivo:** Este projeto resolve o desafio de construir uma pipeline completa de Machine Learning para prever a classificaÃ§Ã£o "Pedra 2024" (Quartzo, Agata, Ametista, TopÃ¡zio) de estudantes baseado em atributos demogrÃ¡ficos (Idade, GÃªnero) e atributos acadÃªmicos (Fase, Ano Ingresso, etc.).

**SoluÃ§Ã£o Proposta:** ConstruÃ§Ã£o de uma pipeline em Python utilizando `scikit-learn` para processamento e treinamento de um modelo *Random Forest*, juntamente com o desenvolvimento de uma API via `FastAPI` para deploy e prediÃ§Ãµes em tempo real. Toda a aplicaÃ§Ã£o foi empacotada com o Docker para garantir que pudesse ser executada com o ambiente de maneira isolada. Testes unitÃ¡rios com o `pytest` alcanÃ§aram >90% de code coverage em todo o projeto.

**Stack TecnolÃ³gica:**
- **Linguagem:** Python 3.12
- **Frameworks de ML:** `scikit-learn`, `pandas`, `numpy`
- **API:** `FastAPI`, `Uvicorn`, `Pydantic`
- **SerializaÃ§Ã£o:** `joblib`
- **Testes:** `pytest`, `pytest-cov`
- **Empacotamento:** `Docker`
- **Monitoramento:** Logging bÃ¡sico estruturado para simulaÃ§Ã£o de detecÃ§Ã£o de drift de dados.

# Estrutura do Projeto (DiretÃ³rios e Arquivos)

```bash
ðŸ“¦ fiap-mleng-datathon-predictive-model
 â”£ ðŸ“‚ app
 â”ƒ â”£ ðŸ“œ main.py                  # Ponto de entrada da API FastAPI
 â”ƒ â”£ ðŸ“œ schemas.py               # Modelos Pydantic (Request/Response)
 â”£ ðŸ“‚ data
 â”ƒ â”£ ðŸ“œ BASE DE DADOS...xlsx     # Base de dados (deve conter a aba PEDE2024)
 â”£ ðŸ“‚ models
 â”ƒ â”£ ðŸ“œ preprocessor.joblib      # Artefato da pipeline de transformaÃ§Ã£o (gerado)
 â”ƒ â”£ ðŸ“œ random_forest_model.joblib # Modelo Random Forest treinado (gerado)
 â”£ ðŸ“‚ src
 â”ƒ â”£ ðŸ“œ config.py                # Caminhos e constantes do sistema
 â”ƒ â”£ ðŸ“œ evaluate.py              # Script para avaliaÃ§Ã£o de mÃ©tricas 
 â”ƒ â”£ ðŸ“œ feature_engineering.py   # Transformadores categÃ³ricos e numÃ©ricos
 â”ƒ â”£ ðŸ“œ preprocessing.py         # Tratamento de nulos e seleÃ§Ã£o de dados
 â”ƒ â”£ ðŸ“œ train.py                 # Script orquestrador de treinamento
 â”ƒ â”£ ðŸ“œ utils.py                 # Fofocas de IO e loggings
 â”£ ðŸ“‚ tests
 â”ƒ â”£ ðŸ“œ test_api.py              # Testes do endpoint de healthcheck
 â”ƒ â”£ ðŸ“œ test_api_predict.py      # Testes do endpoint preditor
 â”ƒ â”£ ðŸ“œ test_feature_engineering.py # Testes dos artefatos de transform
 â”ƒ â”£ ðŸ“œ test_preprocessing.py    # Teste de limpeza de dados
 â”ƒ â”£ ðŸ“œ test_train_evaluate.py   # Testes dos scripts de ML
 â”£ ðŸ“œ Dockerfile                 # Imagem containerizada do ambiente
 â”£ ðŸ“œ README.md                  # Este arquivo
 â”£ ðŸ“œ requirements.txt           # DependÃªncias pip
```

# InstruÃ§Ãµes de Deploy

## Apenas API Local (Sem Docker)

1. Garanta ter o Python 3.12+ em sua mÃ¡quina.
2. Instale as dependÃªncias:
   `pip install -r requirements.txt`
3. Treine o modelo para gerar os arquivos passivos em `/models` antes de testar a base:
   `python -m src.train`
   *(Nota: O script `train.py` Ã© o orquestrador principal. Ele **automaticamente** aciona os mÃ³dulos `preprocessing.py` e `feature_engineering.py` para limpar a base de dados original de Excel e codificar as features antes do treinamento).*
   
4. Avalie as mÃ©tricas:
   `python -m src.evaluate`
5. Rodado a API local:
   `uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload`
6. Rode os testes rodando a bateria com coverage:
   Para que o Python saiba a raiz do pacote dos testes, insira o `PYTHONPATH` antes de rodar o comando:
   No **Windows PowerShell**:
   ```powershell
   $env:PYTHONPATH="."; python -m pytest --cov=src --cov=app tests/
   ```
   No **Linux/Mac**:
   ```bash
   PYTHONPATH="." python -m pytest --cov=src --cov=app tests/
   ```

## Ambiente Containerizado (Docker - Recomendado)

Para subir o sistema isolado em um container:
1. Certifique-se de que treinou o modelo localmente via `python src/train.py` para nÃ£o faltar os arquivos `.joblib` em `./models/` na hora de exportar a imagem. 
2. Construa a Imagem Docker (na pasta raiz):
   ```bash
   docker build -t datathon-model:latest .
   ```
3. Execute o Container:
   ```bash
   docker run -p 8000:8000 datathon-model:latest
   ```
   A aplicaÃ§Ã£o subirÃ¡ no servidor uvicorn apontando para a porta 8000 na sua mÃ¡quina host.

# Exemplos de Chamadas Ã  API

A API expÃµe o endpoint de prediÃ§Ãµes `/predict`. Abaixo exemplos utilizando cURL para validar:

### Health Check 

```bash
curl -X GET http://localhost:8000/
```
**Resposta:**
```json
{
  "status": "ok",
  "message": "API estÃ¡ rodando."
}
```

### Predict 

```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
            "Fase": "2A",
            "Idade": 15,
            "Genero": "Feminino",
            "Ano_ingresso": 2021,
            "Instituicao_de_ensino": "PÃºblica",
            "Fase_Ideal": "Fase 2 (5Âº e 6Âº ano)",
            "Defasagem": -1
         }'
```
**Resposta Esperada:**
```json
{
  "pedra_2024": "Quartzo",
  "versao_modelo": "1.0.0"
}
```

### DicionÃ¡rio de Inputs (Valores VÃ¡lidos)

Para garantir o melhor funcionamento do modelo, o JSON enviado na requisiÃ§Ã£o deve conter os valores dentro das categorias que existiam na base original do treinamento. Caso valores desconhecidos sejam enviados para as variÃ¡veis textuais, o modelo os ignorarÃ¡ estatisticamente.

| Campo (JSON)            | Tipo      | O que espera / Exemplos Exatos |
|--------------------------|-----------|--------------------------------|
| **Fase**                 | String    | Turma atual do aluno. Um dos 60+ valores descritos na base (Ex: `ALFA`, `1A`, `2A`, `3G`, `4L`, `5M`, `7A`, etc). |
| **Idade**                | Inteiro   | Idade do aluno. (Ex: `15`, `18`, `20`). |
| **Genero**               | String    | Exatamente: `Masculino` ou `Feminino`. |
| **Ano_ingresso**         | Inteiro   | Ano de entrada do aluno na organizaÃ§Ã£o (Ex: `2019`, `2021`, `2024`). |
| **Instituicao_de_ensino**| String    | Exatamente um entre: `PÃºblica`, `Privada`, `Privada - Programa de apadrinhamento`, `Privada - Programa de Apadrinhamento`, `Concluiu o 3Âº EM`, `Privada *Parcerias com Bolsa 100%`, `Desconhecido`. |
| **Fase_Ideal**           | String    | Exatamente um entre: `ALFA (1Âº e 2Âº ano)`, `Fase 1 (3Âº e 4Âº ano)`, `Fase 2 (5Âº e 6Âº ano)`, `Fase 3 (7Âº e 8Âº ano)`, `Fase 4 (9Âº ano)`, `Fase 5 (1Âº EM)`, `Fase 6 (2Âº EM)`, `Fase 7 (3Âº EM)`. |
| **Defasagem**            | Inteiro   | NÃºmero <= 0 indicando retenÃ§Ã£o. (Ex: `0`, `-1`, `-2`, `-4`). |

# Etapas do Pipeline de Machine Learning

Foram codificadas de forma modularizada no diretÃ³rio `src/`:

1. **PrÃ©-processamento dos Dados (`preprocessing.py`):**
   Limpeza bÃ¡sica como dropar dados com variavel target faltante (Pedra 2024=nulo), filtra linhas cujos alvos contÃªm descriÃ§Ãµes invÃ¡lidas sobre os quatro grupos esperados. Preenchimento de dados numÃ©ricos omissos com mediana da prÃ³pria coluna ou strings categÃ³ricas com `"Desconhecido"`.

2. **Engenharia de Features (`feature_engineering.py`):**
   Uso do `ColumnTransformer` (sci-kit learn). A codificaÃ§Ã£o divide atributos:
   - NumÃ©ricos e "Ano ingresso": Escalamento via `StandardScaler` e imputaÃ§Ã£o com Mediana.
   - CategÃ³ricos/Ordinais (`GÃªnero`, `InstituiÃ§Ã£o`, `Fase`): ImputaÃ§Ã£o constante para omissos e One-Hot Encoder para expansÃ£o categÃ³rica vetorial livre de suposiÃ§Ã£o de grandeza. O Transformador compÃµe a "pipeline" completa que depois Ã© unida ao exportÃ¡vel (`joblib`).

3. **Treinamento e ValidaÃ§Ã£o (`train.py` && `evaluate.py`):**
   Treinamento utiliza modelo Random Forest com `class_weight='balanced'` por conta nativa do banco de dados ser desequilibrado nos 4 rÃ³tulos (HÃ¡ massivamente mais classificaÃ§Ã£o de grupo "Quartzo"). Ã‰ utilizado RandomForest por capturar fronteiras nÃ£o lineares sem precisar de otimizaÃ§Ãµes de gradiente robustas ou customizaÃ§Ãµes profundas para obter Ã³timos scores na modelagem.
   
   **Resultados da AvaliaÃ§Ã£o (Evaluation):**
   O script `evaluate.py` analisa o poder do modelo perante os dados tratados. Ao executar em todo o *Dataset* base (para checagem do *fit* no desafio atual), ele mostra:
   - **Accuracy**: ~`0.69`
   - **F1-Score (Weighted)**: ~`0.69`
   
   **Por que o F1-Score?**
   A distribuiÃ§Ã£o das "Pedras" tende a ser desbalanceada. O F1 traz a mÃ©dia harmÃ´nica entre a PrecisÃ£o e o Recall, medindo o quanto o modelo acerta a classe especÃ­fica (Precision) e garante a captaÃ§Ã£o da grande maioria das instÃ¢ncias daquela classe (Recall). O algoritmo em Random Forest atende bem, pois garante o aprendizado das relaÃ§Ãµes nÃ£o lineares sem precisar de extrema arquitetura de hiperparÃ¢metros, diminuindo a chance de Overfitting que modelos menores teriam.

4. **PersistÃªncia (`utils.py`):**
   O prÃ©-processamento treinado e as matrizes internas de florestas sÃ£o salvas para serem acopladas e enviadas Ã  API sem vazar dados entre as partiÃ§Ãµes.

5. **Monitoramento Local (SimulaÃ§Ã£o de Data Drift):**
   No ambiente atual, implementamos a fundaÃ§Ã£o para o monitoramento de modelos em produÃ§Ã£o utilizando **Logs Estruturados**. 
   - **Como funciona hoje:** Toda vez que a API recebe dados para prediÃ§Ã£o, o mÃ³dulo `app/main.py` registra (log) as caracterÃ­sticas do aluno consultado diretamente na saÃ­da do terminal/container.
   - **EvoluÃ§Ã£o para ProduÃ§Ã£o:** Num cenÃ¡rio real cloud, esses logs de inferÃªncia seriam capturados automaticamente por ferramentas de observabilidade (ex: Datadog, AWS CloudWatch ou a stack ELK - Elasticsearch, Logstash, Kibana). Com os dados centralizados nesses observadores, criarÃ­amos *Dashboards* para comparar a distribuiÃ§Ã£o de atributos (ex: Idade, Fase) enviados pelos usuÃ¡rios contra a distribuiÃ§Ã£o dos dados de quando o modelo foi treinado. Se houver uma divergÃªncia alta (fenÃ´meno conhecido como **Data Drift**), a equipe de dados recebe um alerta indicando que o modelo pode estar perdendo performance e precisa ser retreinado com informaÃ§Ãµes mais recentes.
